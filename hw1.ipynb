{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задания\n",
    "\n",
    "1. (1 балл) Подготовить мини-корпус (4-5 текстов или до 10 тысяч токенов) с разметкой ключевых слов. \n",
    "Предполагается, что вы найдете источник текстов, в котором **уже выделены** ключевые слова.\n",
    "Укажите источник корпуса и опишите, в каком виде там были представлены ключевые слова. **yes**\n",
    "\n",
    "2. (2 балла) Разметить ключевые слова самостоятельно. Оценить пересечение с имеющейся разметкой.\n",
    "Составить эталон разметки (например, пересечение или объединение вашей разметки и исходной). **yes**\n",
    "\n",
    "3. (2 балла) Применить к этому корпусу 3 метода извлечения ключевых слов на выбор: RAKE, TextRank, tf idf, OKAPI BM25. \n",
    "**yes**\n",
    "\n",
    "4. (2 балла) Составить морфологические/синтаксические шаблоны для ключевых слов и фраз, выделить соответствующие им подстроки из корпуса (например, именные группы Adj+Noun).\n",
    "Применить эти фильтры к спискам ключевых слов. **yes**\n",
    "\n",
    "4. (2  балла) Оценить точность, полноту, F-меру выбранных методов относительно эталона:\n",
    "с учётом морфосинтаксических шаблонов и без них. **yes**\n",
    "\n",
    "5. (1 балл) Описать ошибки автоматического выделения ключевых слов (что выделяется лишнее, что не выделяется);\n",
    "предложить свои методы решения этих проблем. **yes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Я нашла [список датасетов для keyword extraction](https://github.com/LIAAD/KeywordExtractor-Datasets) и взяла оттуда датасет SemEval2017, потому что мне нравится идея автоматически генерировать ключевые слова для научных статей. В датасете для каждого файла с текстом был файл с ключевыми словами, по одному сочетанию на строку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала соберу датафрейм из датасета: соединю текстовые файлы с приписанными им списками ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(data_folder):\n",
    "    text_files_paths = []\n",
    "    kw_files_paths = []\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        for name in files:\n",
    "            path = os.path.join(root, name)\n",
    "            if name.endswith('.txt'):\n",
    "                text_files_paths.append(path)\n",
    "            if name.endswith('.key'):\n",
    "                kw_files_paths.append(path)\n",
    "            else:\n",
    "                continue\n",
    "    return text_files_paths, kw_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files_paths, kw_files_paths = find_files('SemEval2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sorted_tuple(file_paths_list):\n",
    "    sorted_by_filename = []\n",
    "    for path in file_paths_list:\n",
    "        file = path.split('/')[2]\n",
    "        sorted_by_filename.append((path, file))\n",
    "    sorted_by_filename.sort(key=lambda x: x[1])\n",
    "    return sorted_by_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(sorted_texts_paths, sorted_keyword_paths):\n",
    "    df = pd.DataFrame(columns = ['text', 'keywords'])\n",
    "    for text_path, keyword_path in zip(sorted_texts_paths, sorted_keyword_paths):\n",
    "        with open(text_path[0], 'r', encoding='utf-8') as text_file:\n",
    "            text = text_file.read()\n",
    "        with open(keyword_path[0], 'r', encoding='utf-8') as keyword_file:\n",
    "            keywords = keyword_file.read()\n",
    "            keywords = \",\".join(keywords.split('\\n'))\n",
    "        single_text_df = pd.DataFrame({'text': [text], 'keywords': [keywords]})\n",
    "        df = pd.concat([df, single_text_df], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = create_sorted_tuple(text_files_paths)\n",
    "b = create_sorted_tuple(kw_files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complex Langevin (CL) dynamics  [1,2] provides...</td>\n",
       "      <td>CL,complexified configuration space,Complex La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nuclear theory devoted major efforts since 4 d...</td>\n",
       "      <td>C60,combining quantum features,field of cluste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The next important step might be the derivatio...</td>\n",
       "      <td>continuum space-time,Dirac equation,future res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This work shows how our approach based on the ...</td>\n",
       "      <td>class virial expansions,field partition functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fluctuating vacuum is a general feature of q...</td>\n",
       "      <td>a collection of fermionic fields describing co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Complex Langevin (CL) dynamics  [1,2] provides...   \n",
       "0  Nuclear theory devoted major efforts since 4 d...   \n",
       "0  The next important step might be the derivatio...   \n",
       "0  This work shows how our approach based on the ...   \n",
       "0  A fluctuating vacuum is a general feature of q...   \n",
       "\n",
       "                                            keywords  \n",
       "0  CL,complexified configuration space,Complex La...  \n",
       "0  C60,combining quantum features,field of cluste...  \n",
       "0  continuum space-time,Dirac equation,future res...  \n",
       "0  class virial expansions,field partition functi...  \n",
       "0  a collection of fermionic fields describing co...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраню датафрейм в отдельный файл, чтобы потом пользоваться им"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('keword_extraction_semeval.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('keword_extraction_semeval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставлю 5 рандомных текстов и размечу для них ключевые слова вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>This paper presents general results on the Jav...</td>\n",
       "      <td>compare just the constant static trees,compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>This section is devoted to the discretization ...</td>\n",
       "      <td>derivation of the semi-discrete advection–diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>In this Letter, we present results of a relati...</td>\n",
       "      <td>Bethe–Salpeter equation,calculate the average ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Max-linear programs have been used to describe...</td>\n",
       "      <td>adapt the existing methods for finding real so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>We propose an equilibrium model that allows to...</td>\n",
       "      <td>analyze different approaches to recover networ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "454  This paper presents general results on the Jav...   \n",
       "73   This section is devoted to the discretization ...   \n",
       "310  In this Letter, we present results of a relati...   \n",
       "175  Max-linear programs have been used to describe...   \n",
       "332  We propose an equilibrium model that allows to...   \n",
       "\n",
       "                                              keywords  \n",
       "454  compare just the constant static trees,compari...  \n",
       "73   derivation of the semi-discrete advection–diff...  \n",
       "310  Bethe–Salpeter equation,calculate the average ...  \n",
       "175  adapt the existing methods for finding real so...  \n",
       "332  analyze different approaches to recover networ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper presents general results on the Java source code snippet detection problem. We propose the tool which uses graph and subgraph isomorphism detection. A number of solutions for all of these tasks have been proposed in the literature. However, although that all these solutions are really fast, they compare just the constant static trees. Our solution offers to enter an input sample dynamically with the Scripthon language while preserving an acceptable speed. We used several optimizations to achieve very low number of comparisons during the matching algorithm.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_w1 = [\n",
    "    'Java',\n",
    "    'source code snippet detection problem',\n",
    "    'isomorphism detection',\n",
    "    'Scripthon'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This section is devoted to the discretization of the advection–diffusion equation and to the analysis of dispersion and diffusion eigencurves for different polynomial orders. The spectral/hp continuous Galerkin method considered closely resembles the formulation presented in [7]. Sec. 2.1 describes in detail the derivation of the semi-discrete advection–diffusion problem as applied to wave-like solutions, from which the relevant eigencurves can be obtained. The inviscid case (linear advection) is then addressed in Sec. 2.2, where the role of primary and secondary eigencurves is discussed from the perspective introduced in [9]. The viscous case is subsequently considered in Sec. 2.3, where eigencurves are shown to feature irregular oscillations for problems strongly dominated by either convection or diffusion.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_w2 = [\n",
    "    'advection–diffusion equation',\n",
    "    'dispersion and diffusion eigencurves',\n",
    "    'Galerkin method',\n",
    "    'eigencurves'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this Letter, we present results of a relativistic calculation of decay constants in the framework of full Salpeter equation. The full Salpeter equation is a relativistic equation describing a bound state. Since this method has a very solid basis in quantum field theory, it is very good in describing a bound state which is a relativistic system. In a previous paper [16], we solved the instantaneous Bethe–Salpeter equation [17], which is also called full Salpeter equation [18]. After we solved the full Salpeter equation, we obtained the relativistic wave function of the bound state. We used this wave function to calculate the average kinetic energy of the heavy quark inside a heavy meson in 0− state, and obtained values which agree very well with recent experiments. We also found there that the relativistic corrections are quite large and cannot be ignored [16]. In this Letter we use this method to predict the values of decay constants of heavy mesons in 0− state.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'].tolist()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_w3 = [\n",
    "    'relativistic calculation of decay constants',\n",
    "    'full Salpeter equation',\n",
    "    'quantum field theory',\n",
    "    'decay constants'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max-linear programs have been used to describe optimisation problems for multiprocessor interactive systems. In some instances the variables used in this model are required to be integer; however, no method seems to exist for finding integer solutions to max-linear programs.For a generic class of matrices, we show that integer solutions to two-sided max-linear systems and programs can be found in polynomial time. For general matrices, we adapt the existing methods for finding real solutions to obtain algorithms for finding integer solutions.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'].tolist()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_w4 = [\n",
    "    'Max-linear programs',\n",
    "    'matrices',\n",
    "    'multiprocessor interactive systems',\n",
    "    'optimisation'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose an equilibrium model that allows to analyze the long-run impact of the electricity market design on transmission line expansion by the regulator and investment in generation capacity by private firms in liberalized electricity markets. The model incorporates investment decisions of the transmission system operator and private firms in expectation of an energy-only market and cost-based redispatch. In different specifications we consider the cases of one vs. multiple price zones (market splitting) and analyze different approaches to recover network cost—in particular lump sum, generation capacity based, and energy based fees. In order to compare the outcomes of our multilevel market model with a first best benchmark, we also solve the corresponding integrated planner problem. Using two test networks we illustrate that energy-only markets can lead to suboptimal locational decisions for generation capacity and thus imply excessive network expansion. Market splitting heals these problems only partially. These results are valid for all considered types of network tariffs, although investment slightly differs across those regimes.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'].tolist()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_w5 = [\n",
    "    'equilibrium model',\n",
    "    'electricity market',\n",
    "    'transmission line',\n",
    "    'investment',\n",
    "    'market splitting',\n",
    "    'integrated planner problem',\n",
    "    'energy-only markets'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_extracted_keywords = [k_w1, k_w2, k_w3, k_w4, k_w5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я разметила слова, теперь нужно придумать как сранивать списки слов между собой и получать precision, recall и F-measure.\n",
    "\n",
    "Думаю сделать это так: для каждого элемента эталонного списка ключевых слов буду смотреть является ли он подстрокой какого-то элемента из сравниваемого списка ключевых слов и наоборот.\n",
    "\n",
    "Я хочу, чтобы ```equilibrium model``` и ```equilibrium models``` считались успехом. \n",
    "\n",
    " ```True Positive``` - элемент одного списка является подстрокой элемента другого списка.\n",
    " \n",
    " ```False Negative```- для элемента из эталонного списка не нашлось элемента из сравниваемого списка, с которым можно было бы вступить в отношения подстрокования. \n",
    " \n",
    " ```False Positive``` - для элемента из сравниваемого списка не нашлось элемента из эталонного списка, с которым можно было бы вступить в отношения подстрокования. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_fn_fp(gold_kw, annotated_kw):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    annotated_kw_matched = []\n",
    "    gold_kw_matched = []\n",
    "    for gold_keyword in gold_kw:\n",
    "            for annotated_keyword in annotated_kw:\n",
    "                if gold_keyword.find(annotated_keyword) == 0 or annotated_keyword.find(gold_keyword) == 0:\n",
    "                    if annotated_keyword not in annotated_kw_matched:\n",
    "                        tp += 1\n",
    "                        annotated_kw_matched.append(annotated_keyword)\n",
    "                        gold_kw_matched.append(gold_keyword)\n",
    "                    else:\n",
    "                        continue\n",
    "    fn = len(gold_kw) - len(gold_kw_matched)\n",
    "    fp = len(annotated_kw) - len(annotated_kw_matched)\n",
    "    return tp, fn, fp   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрю, насколько моя разметка совпадает с эталонной. Я буду считать точность, полноту и F-меру для каждого текста отдельно и потом посмотрю на их среднее арифметическое как на метрику по всей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f_measure(tp, fn, fp):\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    try:\n",
    "        f_measure = 2 * ((precision * recall)/(precision + recall))\n",
    "    except ZeroDivisionError:\n",
    "        f_measure = 0\n",
    "    return precision, recall, f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_kw_lists = []\n",
    "for text_keywords in test_df.keywords.tolist():\n",
    "    kw_list = text_keywords.split(',')\n",
    "    kw_list.pop()\n",
    "    gold_kw_lists.append(kw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_precision = []\n",
    "texts_recall = []\n",
    "texts_f_measure = []\n",
    "\n",
    "for gold_kw, annotated_kw in zip(gold_kw_lists, manually_extracted_keywords):\n",
    "    tp, fn, fp = tp_fn_fp(gold_kw, annotated_kw)\n",
    "    precision, recall, f_measure = precision_recall_f_measure(tp, fn, fp)\n",
    "    texts_precision.append(precision)\n",
    "    texts_recall.append(recall)\n",
    "    texts_f_measure.append(f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PRECISION on 5 texts: 0.5857142857142857\n",
      "Average RECALL on 5 texts: 0.2204184704184704\n",
      "Average F-MEASURE on 5 texts: 0.3133479853479853\n"
     ]
    }
   ],
   "source": [
    "print(f'Average PRECISION on 5 texts: {statistics.mean(texts_precision)}')\n",
    "print(f'Average RECALL on 5 texts: {statistics.mean(texts_recall)}')\n",
    "print(f'Average F-MEASURE on 5 texts: {statistics.mean(texts_f_measure)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По метрикам я вижу, что моя разметка гораздо менее полная чем разметка в датасете - я выделила лишь 22% ключевых слов, выделенных аннотаторами.\n",
    "\n",
    "В датасете ключевые слова к статьям размечали люди, которые их читали. Я читала только абстракты и не шарю в предметных областях статей, поэтому буду считать разметку датасета эталонной и дальше считать все метрики только по ней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение ключевых слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моя работа с методами извлечения ключевых слов основана на следующих предположениях:\n",
    "\n",
    "1) Регистр не важен и можно сделать lower() для всего текста\n",
    "\n",
    "2) Все стоп-слова нужно удалять\n",
    "\n",
    "3) Все знаки, кроме буквенных надо удалять\n",
    "\n",
    "4) Нужно лемматизировать текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extended_stopwords_towards_nlp.txt', 'r', encoding='utf-8') as file:\n",
    "    raw = file.read()\n",
    "stopwords = raw.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern\n",
    "from pattern.en import lemma, lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^-a-z]', ' ', text)\n",
    "    text = \" \".join(text.split())\n",
    "    lemmatized_text = [lemma(wd) for wd in text.split() if lemma(wd) not in stopwords]\n",
    "    text = \" \".join(lemmatized_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_with_RAKE(texts):\n",
    "    kws_of_texts_collection = []\n",
    "    rake = RAKE.Rake(stopwords)\n",
    "    for text in texts:\n",
    "        text_kw_list = []\n",
    "        text_kws = rake.run(text, maxWords=3, minFrequency=2)\n",
    "        for kw in text_kws:\n",
    "            text_kw_list.append(kw[0])\n",
    "        text_kw_list = \",\".join(text_kw_list)\n",
    "        kws_of_texts_collection.append(text_kw_list)\n",
    "    return kws_of_texts_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 19.5 ms, total: 2.92 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['RAKE_keywords'] = extract_keywords_with_RAKE(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>RAKE_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complex Langevin (CL) dynamics  [1,2] provides...</td>\n",
       "      <td>CL,complexified configuration space,Complex La...</td>\n",
       "      <td>cl,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nuclear theory devoted major efforts since 4 d...</td>\n",
       "      <td>C60,combining quantum features,field of cluste...</td>\n",
       "      <td>field,10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The next important step might be the derivatio...</td>\n",
       "      <td>continuum space-time,Dirac equation,future res...</td>\n",
       "      <td>continuum space-time,continuum limit,objects h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work shows how our approach based on the ...</td>\n",
       "      <td>class virial expansions,field partition functi...</td>\n",
       "      <td>solution,form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fluctuating vacuum is a general feature of q...</td>\n",
       "      <td>a collection of fermionic fields describing co...</td>\n",
       "      <td>nuclear physics,nucleon,surface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Complex Langevin (CL) dynamics  [1,2] provides...   \n",
       "1  Nuclear theory devoted major efforts since 4 d...   \n",
       "2  The next important step might be the derivatio...   \n",
       "3  This work shows how our approach based on the ...   \n",
       "4  A fluctuating vacuum is a general feature of q...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  CL,complexified configuration space,Complex La...   \n",
       "1  C60,combining quantum features,field of cluste...   \n",
       "2  continuum space-time,Dirac equation,future res...   \n",
       "3  class virial expansions,field partition functi...   \n",
       "4  a collection of fermionic fields describing co...   \n",
       "\n",
       "                                       RAKE_keywords  \n",
       "0                                             cl,10]  \n",
       "1                                          field,10]  \n",
       "2  continuum space-time,continuum limit,objects h...  \n",
       "3                                      solution,form  \n",
       "4                    nuclear physics,nucleon,surface  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказалось, что RAKE на этих текстах работает намного хуже, если делать препроцессинг. Поэтому я не стала его делать, посмотрю, как это влияет на другие методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_with_TextRank(texts):\n",
    "    kws_of_texts_collection = []\n",
    "    for text in texts:\n",
    "        text = preprocess_text(text)\n",
    "        text_kw_list = []\n",
    "        text_kws = keywords(text, pos_filter=[], scores=True)\n",
    "        for kw in text_kws:\n",
    "            text_kw_list.append(kw[0])\n",
    "        text_kw_list = \",\".join(text_kw_list)\n",
    "        kws_of_texts_collection.append(text_kw_list)\n",
    "    return kws_of_texts_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 184 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['TextRank_keywords'] = extract_keywords_with_TextRank(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>RAKE_keywords</th>\n",
       "      <th>TextRank_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complex Langevin (CL) dynamics  [1,2] provides...</td>\n",
       "      <td>CL,complexified configuration space,Complex La...</td>\n",
       "      <td>cl,10]</td>\n",
       "      <td>result,thi,field theory,distribution,rely samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nuclear theory devoted major efforts since 4 d...</td>\n",
       "      <td>C60,combining quantum features,field of cluste...</td>\n",
       "      <td>field,10]</td>\n",
       "      <td>quantum,approach,dynamic,dynamical,development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The next important step might be the derivatio...</td>\n",
       "      <td>continuum space-time,Dirac equation,future res...</td>\n",
       "      <td>continuum space-time,continuum limit,objects h...</td>\n",
       "      <td>continuum,treatment,description,lattice partic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work shows how our approach based on the ...</td>\n",
       "      <td>class virial expansions,field partition functi...</td>\n",
       "      <td>solution,form</td>\n",
       "      <td>approach,solution,partition,equation,class,for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fluctuating vacuum is a general feature of q...</td>\n",
       "      <td>a collection of fermionic fields describing co...</td>\n",
       "      <td>nuclear physics,nucleon,surface</td>\n",
       "      <td>field,bag,nucleon,scale,vacuum,force,surface,c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Complex Langevin (CL) dynamics  [1,2] provides...   \n",
       "1  Nuclear theory devoted major efforts since 4 d...   \n",
       "2  The next important step might be the derivatio...   \n",
       "3  This work shows how our approach based on the ...   \n",
       "4  A fluctuating vacuum is a general feature of q...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  CL,complexified configuration space,Complex La...   \n",
       "1  C60,combining quantum features,field of cluste...   \n",
       "2  continuum space-time,Dirac equation,future res...   \n",
       "3  class virial expansions,field partition functi...   \n",
       "4  a collection of fermionic fields describing co...   \n",
       "\n",
       "                                       RAKE_keywords  \\\n",
       "0                                             cl,10]   \n",
       "1                                          field,10]   \n",
       "2  continuum space-time,continuum limit,objects h...   \n",
       "3                                      solution,form   \n",
       "4                    nuclear physics,nucleon,surface   \n",
       "\n",
       "                                   TextRank_keywords  \n",
       "0  result,thi,field theory,distribution,rely samp...  \n",
       "1  quantum,approach,dynamic,dynamical,development...  \n",
       "2  continuum,treatment,description,lattice partic...  \n",
       "3  approach,solution,partition,equation,class,for...  \n",
       "4  field,bag,nucleon,scale,vacuum,force,surface,c...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мне нравится, что TextRank выделил совсем другие ключевые слова. Этот метод лучше работает с препроцессингом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yet Another Keyword Extractor (Yake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor(dedupLim=0.9, dedupFunc='seqm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_with_Yake(texts):\n",
    "    kws_of_texts_collection = []\n",
    "    for text in texts:\n",
    "        text = preprocess_text(text)\n",
    "        text_kw_list = []\n",
    "        text_kws = kw_extractor.extract_keywords(text)\n",
    "        for kw in text_kws:\n",
    "            text_kw_list.append(kw[0])\n",
    "        text_kw_list = \",\".join(text_kw_list)\n",
    "        kws_of_texts_collection.append(text_kw_list)\n",
    "    return kws_of_texts_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 1.06 s, total: 2min 15s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Yake_keywords'] = extract_keywords_with_Yake(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>RAKE_keywords</th>\n",
       "      <th>TextRank_keywords</th>\n",
       "      <th>Yake_keywords</th>\n",
       "      <th>RAKE_keywords_filtered</th>\n",
       "      <th>TextRank_keywords_filtered</th>\n",
       "      <th>Yake_keywords_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complex Langevin (CL) dynamics  [1,2] provides...</td>\n",
       "      <td>CL,complexified configuration space,Complex La...</td>\n",
       "      <td>cl,10]</td>\n",
       "      <td>result,thi,field theory,distribution,rely samp...</td>\n",
       "      <td>dynamic provide approach,provide approach circ...</td>\n",
       "      <td></td>\n",
       "      <td>sign problem</td>\n",
       "      <td>provide approach,approach circumvent,year numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nuclear theory devoted major efforts since 4 d...</td>\n",
       "      <td>C60,combining quantum features,field of cluste...</td>\n",
       "      <td>field,10]</td>\n",
       "      <td>quantum,approach,dynamic,dynamical,development...</td>\n",
       "      <td>treat thi semi,theory devote major,devote majo...</td>\n",
       "      <td></td>\n",
       "      <td>development laser</td>\n",
       "      <td>theory devote,major effort,major effort,effort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The next important step might be the derivatio...</td>\n",
       "      <td>continuum space-time,Dirac equation,future res...</td>\n",
       "      <td>continuum space-time,continuum limit,objects h...</td>\n",
       "      <td>continuum,treatment,description,lattice partic...</td>\n",
       "      <td>object hop lattice,knowledge object hop,step d...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>knowledge object,object hop,step derivation,in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work shows how our approach based on the ...</td>\n",
       "      <td>class virial expansions,field partition functi...</td>\n",
       "      <td>solution,form</td>\n",
       "      <td>approach,solution,partition,equation,class,for...</td>\n",
       "      <td>van der waal,describe van der,reproduce van de...</td>\n",
       "      <td></td>\n",
       "      <td>phase transition</td>\n",
       "      <td>virial expansion,base combination,mechanic non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fluctuating vacuum is a general feature of q...</td>\n",
       "      <td>a collection of fermionic fields describing co...</td>\n",
       "      <td>nuclear physics,nucleon,surface</td>\n",
       "      <td>field,bag,nucleon,scale,vacuum,force,surface,c...</td>\n",
       "      <td>fermionic field describe,fluctuate vacuum gene...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fermionic field,field describe,boundary condit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Complex Langevin (CL) dynamics  [1,2] provides...   \n",
       "1  Nuclear theory devoted major efforts since 4 d...   \n",
       "2  The next important step might be the derivatio...   \n",
       "3  This work shows how our approach based on the ...   \n",
       "4  A fluctuating vacuum is a general feature of q...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  CL,complexified configuration space,Complex La...   \n",
       "1  C60,combining quantum features,field of cluste...   \n",
       "2  continuum space-time,Dirac equation,future res...   \n",
       "3  class virial expansions,field partition functi...   \n",
       "4  a collection of fermionic fields describing co...   \n",
       "\n",
       "                                       RAKE_keywords  \\\n",
       "0                                             cl,10]   \n",
       "1                                          field,10]   \n",
       "2  continuum space-time,continuum limit,objects h...   \n",
       "3                                      solution,form   \n",
       "4                    nuclear physics,nucleon,surface   \n",
       "\n",
       "                                   TextRank_keywords  \\\n",
       "0  result,thi,field theory,distribution,rely samp...   \n",
       "1  quantum,approach,dynamic,dynamical,development...   \n",
       "2  continuum,treatment,description,lattice partic...   \n",
       "3  approach,solution,partition,equation,class,for...   \n",
       "4  field,bag,nucleon,scale,vacuum,force,surface,c...   \n",
       "\n",
       "                                       Yake_keywords RAKE_keywords_filtered  \\\n",
       "0  dynamic provide approach,provide approach circ...                          \n",
       "1  treat thi semi,theory devote major,devote majo...                          \n",
       "2  object hop lattice,knowledge object hop,step d...                          \n",
       "3  van der waal,describe van der,reproduce van de...                          \n",
       "4  fermionic field describe,fluctuate vacuum gene...                          \n",
       "\n",
       "  TextRank_keywords_filtered  \\\n",
       "0               sign problem   \n",
       "1          development laser   \n",
       "2                              \n",
       "3           phase transition   \n",
       "4                              \n",
       "\n",
       "                              Yake_keywords_filtered  \n",
       "0  provide approach,approach circumvent,year numb...  \n",
       "1  theory devote,major effort,major effort,effort...  \n",
       "2  knowledge object,object hop,step derivation,in...  \n",
       "3  virial expansion,base combination,mechanic non...  \n",
       "4  fermionic field,field describe,boundary condit...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова другие ключевые слова. Этот метод медленнее остальных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаблоны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я буду использовать следующие шаблоны:\n",
    " \n",
    "1) VERB NOUN - Measure complexity\n",
    "2) ADJ NOUN - Complex systems\n",
    "3) NOUN NOUN - Knowledge object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizavetaersova/miniconda3/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую код из [ответа на стаковерфлоу](https://stackoverflow.com/questions/55393087/pos-pattern-mining-with-spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    [{'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "    [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "    [{'POS': 'NOUN'}, {'POS': 'NOUN'}]\n",
    "    ]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"verb-noun\", None, patterns[0])\n",
    "matcher.add(\"adj-noun\", None, patterns[1])\n",
    "matcher.add(\"noun-noun\", None, patterns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kw(keyword_string):\n",
    "    filtered_kws = []\n",
    "    keywords = keyword_string.split(',')\n",
    "    for keyword in keywords:\n",
    "        keyword = nlp(keyword)\n",
    "        matches = matcher(keyword)\n",
    "        for match_id, start, end in matches:\n",
    "            string_id = nlp.vocab.strings[match_id]\n",
    "            span = keyword[start:end]\n",
    "            filtered_kws.append(span.text)\n",
    "    filtered_kws = \",\".join(filtered_kws)\n",
    "    return filtered_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 197 ms, total: 15.8 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['RAKE_keywords_filtered'] = df['RAKE_keywords'].apply(lambda x: str(filter_kw(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 s, sys: 355 ms, total: 34.4 s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['TextRank_keywords_filtered'] = df['TextRank_keywords'].apply(lambda x: str(filter_kw(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 545 ms, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Yake_keywords_filtered'] = df['Yake_keywords'].apply(lambda x: str(filter_kw(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>RAKE_keywords</th>\n",
       "      <th>TextRank_keywords</th>\n",
       "      <th>Yake_keywords</th>\n",
       "      <th>RAKE_keywords_filtered</th>\n",
       "      <th>TextRank_keywords_filtered</th>\n",
       "      <th>Yake_keywords_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complex Langevin (CL) dynamics  [1,2] provides...</td>\n",
       "      <td>CL,complexified configuration space,Complex La...</td>\n",
       "      <td>cl,10]</td>\n",
       "      <td>result,thi,field theory,distribution,rely samp...</td>\n",
       "      <td>dynamic provide approach,provide approach circ...</td>\n",
       "      <td></td>\n",
       "      <td>sign problem</td>\n",
       "      <td>provide approach,approach circumvent,year numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nuclear theory devoted major efforts since 4 d...</td>\n",
       "      <td>C60,combining quantum features,field of cluste...</td>\n",
       "      <td>field,10]</td>\n",
       "      <td>quantum,approach,dynamic,dynamical,development...</td>\n",
       "      <td>treat thi semi,theory devote major,devote majo...</td>\n",
       "      <td></td>\n",
       "      <td>development laser</td>\n",
       "      <td>theory devote,major effort,major effort,effort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The next important step might be the derivatio...</td>\n",
       "      <td>continuum space-time,Dirac equation,future res...</td>\n",
       "      <td>continuum space-time,continuum limit,objects h...</td>\n",
       "      <td>continuum,treatment,description,lattice partic...</td>\n",
       "      <td>object hop lattice,knowledge object hop,step d...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>knowledge object,object hop,step derivation,in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work shows how our approach based on the ...</td>\n",
       "      <td>class virial expansions,field partition functi...</td>\n",
       "      <td>solution,form</td>\n",
       "      <td>approach,solution,partition,equation,class,for...</td>\n",
       "      <td>van der waal,describe van der,reproduce van de...</td>\n",
       "      <td></td>\n",
       "      <td>phase transition</td>\n",
       "      <td>virial expansion,base combination,mechanic non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fluctuating vacuum is a general feature of q...</td>\n",
       "      <td>a collection of fermionic fields describing co...</td>\n",
       "      <td>nuclear physics,nucleon,surface</td>\n",
       "      <td>field,bag,nucleon,scale,vacuum,force,surface,c...</td>\n",
       "      <td>fermionic field describe,fluctuate vacuum gene...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fermionic field,field describe,boundary condit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Complex Langevin (CL) dynamics  [1,2] provides...   \n",
       "1  Nuclear theory devoted major efforts since 4 d...   \n",
       "2  The next important step might be the derivatio...   \n",
       "3  This work shows how our approach based on the ...   \n",
       "4  A fluctuating vacuum is a general feature of q...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  CL,complexified configuration space,Complex La...   \n",
       "1  C60,combining quantum features,field of cluste...   \n",
       "2  continuum space-time,Dirac equation,future res...   \n",
       "3  class virial expansions,field partition functi...   \n",
       "4  a collection of fermionic fields describing co...   \n",
       "\n",
       "                                       RAKE_keywords  \\\n",
       "0                                             cl,10]   \n",
       "1                                          field,10]   \n",
       "2  continuum space-time,continuum limit,objects h...   \n",
       "3                                      solution,form   \n",
       "4                    nuclear physics,nucleon,surface   \n",
       "\n",
       "                                   TextRank_keywords  \\\n",
       "0  result,thi,field theory,distribution,rely samp...   \n",
       "1  quantum,approach,dynamic,dynamical,development...   \n",
       "2  continuum,treatment,description,lattice partic...   \n",
       "3  approach,solution,partition,equation,class,for...   \n",
       "4  field,bag,nucleon,scale,vacuum,force,surface,c...   \n",
       "\n",
       "                                       Yake_keywords RAKE_keywords_filtered  \\\n",
       "0  dynamic provide approach,provide approach circ...                          \n",
       "1  treat thi semi,theory devote major,devote majo...                          \n",
       "2  object hop lattice,knowledge object hop,step d...                          \n",
       "3  van der waal,describe van der,reproduce van de...                          \n",
       "4  fermionic field describe,fluctuate vacuum gene...                          \n",
       "\n",
       "  TextRank_keywords_filtered  \\\n",
       "0               sign problem   \n",
       "1          development laser   \n",
       "2                              \n",
       "3           phase transition   \n",
       "4                              \n",
       "\n",
       "                              Yake_keywords_filtered  \n",
       "0  provide approach,approach circumvent,year numb...  \n",
       "1  theory devote,major effort,major effort,effort...  \n",
       "2  knowledge object,object hop,step derivation,in...  \n",
       "3  virial expansion,base combination,mechanic non...  \n",
       "4  fermionic field,field describe,boundary condit...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблоны отсекли практически всё из Rake и TextRank, а из Yake много чего осталось и это интересно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка метрик работы разных методов с фильтрацией и без"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_metrics(df, column):\n",
    "    gold_kw_lists = []\n",
    "    annotated_keyword_lists = []\n",
    "    for text_kw_string in df.keywords.tolist():\n",
    "        text_gold_kw = text_kw_string.lower().split(',')\n",
    "        text_gold_kw.pop()\n",
    "        gold_kw_lists.append(text_gold_kw)\n",
    "        \n",
    "    for text_kw_string in df[column].tolist():\n",
    "        text_anno_kw = text_kw_string.split(',')\n",
    "        if text_anno_kw == ['']:\n",
    "            text_anno_kw = None\n",
    "        annotated_keyword_lists.append(text_anno_kw)\n",
    "        \n",
    "    texts_precision = []\n",
    "    texts_recall = []\n",
    "    texts_f_measure = []\n",
    "    for gold_kw, annotated_kw in zip(gold_kw_lists, annotated_keyword_lists):\n",
    "        if annotated_kw is not None:\n",
    "            tp, fn, fp = tp_fn_fp(gold_kw, annotated_kw)\n",
    "            precision, recall, f_measure = precision_recall_f_measure(tp, fn, fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f_measure = 0\n",
    "        texts_precision.append(precision)\n",
    "        texts_recall.append(recall)\n",
    "        texts_f_measure.append(f_measure)\n",
    "        \n",
    "    print(column)\n",
    "    print(f'Average PRECISION: {statistics.mean(texts_precision)}')\n",
    "    print(f'Average RECALL: {statistics.mean(texts_recall)}')\n",
    "    print(f'Average F-MEASURE: {statistics.mean(texts_f_measure)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKE_keywords\n",
      "Average PRECISION: 0.4508016862820938\n",
      "Average RECALL: 0.11869674436361802\n",
      "Average F-MEASURE: 0.16550152192298564\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'RAKE_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKE_keywords_filtered\n",
      "Average PRECISION: 0.2260070965505878\n",
      "Average RECALL: 0.027900741556889604\n",
      "Average F-MEASURE: 0.044852879305750874\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'RAKE_keywords_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank_keywords\n",
      "Average PRECISION: 0.34181311569153117\n",
      "Average RECALL: 0.18882842079479797\n",
      "Average F-MEASURE: 0.2350402862371047\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'TextRank_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank_keywords_filtered\n",
      "Average PRECISION: 0.17799188640973632\n",
      "Average RECALL: 0.017052562891098202\n",
      "Average F-MEASURE: 0.03009388238890513\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'TextRank_keywords_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yake_keywords\n",
      "Average PRECISION: 0.11987829614604463\n",
      "Average RECALL: 0.14884229891891954\n",
      "Average F-MEASURE: 0.12746080280606156\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'Yake_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yake_keywords_filtered\n",
      "Average PRECISION: 0.11559734666565397\n",
      "Average RECALL: 0.11288814468625952\n",
      "Average F-MEASURE: 0.10685791642215416\n"
     ]
    }
   ],
   "source": [
    "method_metrics(df, 'Yake_keywords_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно метрикам на этом датасете лучшая F-мера у TextRank_keywords.\n",
    "\n",
    "RAKE реже ошибается, но и предсказывает в целом меньше.\n",
    "\n",
    "YAKE чаще ошибается, но и предсказывает в целом больше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберу ошибки на примере 3 из 5 текстов, где я размечала ключевые слова вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 42 ms, total: 2.66 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "test_df['RAKE_keywords'] = extract_keywords_with_RAKE(test_df['text'].tolist())\n",
    "test_df['TextRank_keywords'] = extract_keywords_with_TextRank(test_df['text'].tolist())\n",
    "test_df['Yake_keywords'] = extract_keywords_with_Yake(test_df['text'].tolist())\n",
    "test_df['RAKE_keywords_filtered'] = test_df['RAKE_keywords'].apply(lambda x: str(filter_kw(x)))\n",
    "test_df['TextRank_keywords_filtered'] = test_df['TextRank_keywords'].apply(lambda x: str(filter_kw(x)))\n",
    "test_df['Yake_keywords_filtered'] = test_df['Yake_keywords'].apply(lambda x: str(filter_kw(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>RAKE_keywords</th>\n",
       "      <th>TextRank_keywords</th>\n",
       "      <th>Yake_keywords</th>\n",
       "      <th>RAKE_keywords_filtered</th>\n",
       "      <th>TextRank_keywords_filtered</th>\n",
       "      <th>Yake_keywords_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>This paper presents general results on the Jav...</td>\n",
       "      <td>compare just the constant static trees,compari...</td>\n",
       "      <td>solutions</td>\n",
       "      <td>number solution,detection,propose,match,paper ...</td>\n",
       "      <td>thi paper general,dure match algorithm,paper g...</td>\n",
       "      <td></td>\n",
       "      <td>number solution</td>\n",
       "      <td>constant static,static tree,enter input,enter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>This section is devoted to the discretization ...</td>\n",
       "      <td>derivation of the semi-discrete advection–diff...</td>\n",
       "      <td>2</td>\n",
       "      <td>eigencurve,discretization advection diffusion,...</td>\n",
       "      <td>thi devote discretization,equation analysi dis...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>polynomial order,order spectral,resemble formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>In this Letter, we present results of a relati...</td>\n",
       "      <td>Bethe–Salpeter equation,calculate the average ...</td>\n",
       "      <td>full salpeter equation,decay constants,bound s...</td>\n",
       "      <td>heavy,state,thi,relativistic calculation,calcu...</td>\n",
       "      <td>full salpeter equation,describe bound state,he...</td>\n",
       "      <td>full salpeter,salpeter equation,bound state</td>\n",
       "      <td>relativistic calculation</td>\n",
       "      <td>full salpeter,salpeter equation,bound state,bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Max-linear programs have been used to describe...</td>\n",
       "      <td>adapt the existing methods for finding real so...</td>\n",
       "      <td>max-linear programs,finding integer solutions</td>\n",
       "      <td>solution,generic,general,integer,matrice</td>\n",
       "      <td>describe optimisation problem,optimisation pro...</td>\n",
       "      <td>finding integer,integer solutions</td>\n",
       "      <td></td>\n",
       "      <td>describe optimisation,optimisation problem,opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>We propose an equilibrium model that allows to...</td>\n",
       "      <td>analyze different approaches to recover networ...</td>\n",
       "      <td>generation capacity,private firms,energy-,anal...</td>\n",
       "      <td>market,network,model,base,investment generatio...</td>\n",
       "      <td>differ acros regime,generation capacity privat...</td>\n",
       "      <td>generation capacity,private firms</td>\n",
       "      <td>investment generation,generation capacity</td>\n",
       "      <td>acros regime,generation capacity,private firm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "454  This paper presents general results on the Jav...   \n",
       "73   This section is devoted to the discretization ...   \n",
       "310  In this Letter, we present results of a relati...   \n",
       "175  Max-linear programs have been used to describe...   \n",
       "332  We propose an equilibrium model that allows to...   \n",
       "\n",
       "                                              keywords  \\\n",
       "454  compare just the constant static trees,compari...   \n",
       "73   derivation of the semi-discrete advection–diff...   \n",
       "310  Bethe–Salpeter equation,calculate the average ...   \n",
       "175  adapt the existing methods for finding real so...   \n",
       "332  analyze different approaches to recover networ...   \n",
       "\n",
       "                                         RAKE_keywords  \\\n",
       "454                                          solutions   \n",
       "73                                                   2   \n",
       "310  full salpeter equation,decay constants,bound s...   \n",
       "175      max-linear programs,finding integer solutions   \n",
       "332  generation capacity,private firms,energy-,anal...   \n",
       "\n",
       "                                     TextRank_keywords  \\\n",
       "454  number solution,detection,propose,match,paper ...   \n",
       "73   eigencurve,discretization advection diffusion,...   \n",
       "310  heavy,state,thi,relativistic calculation,calcu...   \n",
       "175           solution,generic,general,integer,matrice   \n",
       "332  market,network,model,base,investment generatio...   \n",
       "\n",
       "                                         Yake_keywords  \\\n",
       "454  thi paper general,dure match algorithm,paper g...   \n",
       "73   thi devote discretization,equation analysi dis...   \n",
       "310  full salpeter equation,describe bound state,he...   \n",
       "175  describe optimisation problem,optimisation pro...   \n",
       "332  differ acros regime,generation capacity privat...   \n",
       "\n",
       "                          RAKE_keywords_filtered  \\\n",
       "454                                                \n",
       "73                                                 \n",
       "310  full salpeter,salpeter equation,bound state   \n",
       "175            finding integer,integer solutions   \n",
       "332            generation capacity,private firms   \n",
       "\n",
       "                    TextRank_keywords_filtered  \\\n",
       "454                            number solution   \n",
       "73                                               \n",
       "310                   relativistic calculation   \n",
       "175                                              \n",
       "332  investment generation,generation capacity   \n",
       "\n",
       "                                Yake_keywords_filtered  \n",
       "454  constant static,static tree,enter input,enter ...  \n",
       "73   polynomial order,order spectral,resemble formu...  \n",
       "310  full salpeter,salpeter equation,bound state,bo...  \n",
       "175  describe optimisation,optimisation problem,opt...  \n",
       "332  acros regime,generation capacity,private firm,...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare just the constant static trees\n",
      "comparisons\n",
      "enter an input sample dynamically\n",
      "graph and subgraph isomorphism detection\n",
      "Java source code snippet detection\n",
      "matching algorithm\n",
      "preserving an acceptable speed\n",
      "Scripthon language\n",
      "several optimizations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['keywords'].tolist()[0].split(','):\n",
    "    print(keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solutions\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['RAKE_keywords'].tolist()[0].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number solution\n",
      "detection\n",
      "propose\n",
      "match\n",
      "paper general result\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['TextRank_keywords'].tolist()[0].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number solution\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['TextRank_keywords_filtered'].tolist()[0].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi paper general\n",
      "dure match algorithm\n",
      "paper general result\n",
      "general result java\n",
      "result java source\n",
      "java source code\n",
      "source code snippet\n",
      "tool graph subgraph\n",
      "graph subgraph isomorphism\n",
      "fast compare constant\n",
      "compare constant static\n",
      "constant static tree\n",
      "offer enter input\n",
      "enter input sample\n",
      "input sample dynamically\n",
      "sample dynamically scripthon\n",
      "dynamically scripthon language\n",
      "scripthon language preserve\n",
      "language preserve acceptable\n",
      "preserve acceptable speed\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['Yake_keywords'].tolist()[0].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant static\n",
      "static tree\n",
      "enter input\n",
      "enter input\n",
      "input sample\n",
      "scripthon language\n",
      "language preserve\n",
      "acceptable speed\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['Yake_keywords_filtered'].tolist()[0].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибки по **Text1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не выделились имена собственные: ```Java, Scripthon```.\n",
    "\n",
    "Не выделились сочетания длиннее 3 токенов: compare ```just the constant static trees```, ```graph and subgraph isomorphism detection```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivation of the semi-discrete advection–diffusion problem\n",
      "discretization of the advection–diffusion equation\n",
      "dispersion and diffusion eigencurves\n",
      "Galerkin method\n",
      "inviscid case\n",
      "linear advection\n",
      "viscous case\n",
      "wave-like solutions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['keywords'].tolist()[1].split(','):\n",
    "    print(keyword)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['RAKE_keywords'].tolist()[1].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigencurve\n",
      "discretization advection diffusion\n",
      "consider\n",
      "case\n",
      "problem\n",
      "galerkin\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['TextRank_keywords'].tolist()[1].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi devote discretization\n",
      "equation analysi dispersion\n",
      "polynomial order spectral\n",
      "continuou galerkin method\n",
      "closely resemble formulation\n",
      "resemble formulation describe\n",
      "formulation describe detail\n",
      "describe detail derivation\n",
      "detail derivation semi-discrete\n",
      "apply wave-like solution\n",
      "wave-like solution relevant\n",
      "address role primary\n",
      "role primary secondary\n",
      "discuss perspective introduce\n",
      "perspective introduce viscou\n",
      "feature irregular oscillation\n",
      "problem apply wave-like\n",
      "inviscid case linear\n",
      "introduce viscou case\n",
      "viscou case subsequently\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['Yake_keywords'].tolist()[1].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибки по **Text2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделились малозначимые в целом слова: ```case, consider, problem, 2```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bethe–Salpeter equation\n",
      "calculate the average kinetic energy\n",
      "describing a bound state\n",
      "framework of full Salpeter equation\n",
      "full Salpeter equation\n",
      "heavy meson\n",
      "heavy mesons\n",
      "heavy quark\n",
      "obtained values\n",
      "predict the values of decay constants\n",
      "quantum field theory\n",
      "relativistic calculation of decay constants\n",
      "relativistic corrections are quite large\n",
      "relativistic equation\n",
      "relativistic system\n",
      "relativistic wave function of the bound state\n",
      "Salpeter equation\n",
      "solved the full Salpeter equation\n",
      "solved the instantaneous Bethe–Salpeter equation\n",
      "use this method\n",
      "wave function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['keywords'].tolist()[2].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full salpeter equation\n",
      "decay constants\n",
      "bound state\n",
      "0− state\n",
      "letter\n",
      "method\n",
      "solved\n",
      "values\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['RAKE_keywords'].tolist()[2].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heavy\n",
      "state\n",
      "thi\n",
      "relativistic calculation\n",
      "calculate\n",
      "solve\n",
      "constant\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['TextRank_keywords'].tolist()[2].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full salpeter equation\n",
      "describe bound state\n",
      "heavy meson state\n",
      "bound state thi\n",
      "salpeter equation relativistic\n",
      "instantaneou bethe salpeter\n",
      "framework full salpeter\n",
      "call full salpeter\n",
      "bethe salpeter equation\n",
      "salpeter equation call\n",
      "equation full salpeter\n",
      "good describe bound\n",
      "meson state agree\n",
      "solve full salpeter\n",
      "wave function bound\n",
      "function bound state\n",
      "salpeter equation solve\n",
      "solid basi quantum\n",
      "basi quantum field\n",
      "quantum field theory\n"
     ]
    }
   ],
   "source": [
    "for keyword in test_df['Yake_keywords'].tolist()[2].split(','):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибки по **Text3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, Yake всегда выдает триграммы, но как перебрать все варианты н-грамм я не понимаю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод по проблемам и предложения по их решению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Проверять токены и последовательности токенов на бытие NE или именем собственным: к примеру, можно считать все токены, которые капитализированы не в начале предложения - именами собственными.\n",
    "\n",
    "2) Перебирать параметры экстракторов: сначала поискать униграммы, потом биграммы, потом триграммы и включать в итоговую выборку их комбинации.\n",
    "\n",
    "3) Использовать информацию о \"важности\" токена как в TF-IDF, чтобы избегать выделения слов вроде ```consider``` как ключевых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
